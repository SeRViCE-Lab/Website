---
extends: minimal.j2
default_block: main
title: Publications
description: Curriculum Vitae for Olalekan Ogunmolu
---
<!-- Google Anakytics Tracker -->
<!-- Google Anakytics Tracker -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-64680332-3', 'auto');
  ga('send', 'pageview');
  ga('send', 'pageview' '/research.html');
  ga('send', 'pageview' '/speaking.html');
  ga('send', 'pageview'  '/projects.html');
  ga('send', 'pageview' 'http://lakehanne.github.io/');
  ga('send', 'pageview' '/dfwslides');

</script>

  
<html>

<h1>Publications</h1>
<hr/>

<h4><font color="#711E0C">Nonlinear Systems Identification Using Deep Dynamic Neural Networks.</font></h4>
    <p><font color="#110D0C">An investigation of the effectiveness of deep neural networks in the modeling of dynamical systems with complex behavior. Three deep neural network structures are trained on sequential data, and we investigate the effectiveness of these networks in modeling associated characteristics of the underlying dynamical systems. </font><br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>. <font color="#110D0C">To appear in <i>American Control Conference (ACC)</i>. Seattle, WA. May 2017.</font> <br>
    <a href="{{ media_url('Papers/ACC2016/ACC2016.pdf') }}" class="border"><i class="fa fa-file-pdf-o"></i><b>PDF &nbsp;</b></a> 
    <a href="https://arxiv.org/abs/1610.01439"><b> arXiv &nbsp;</b></a> 
    <a href="https://github.com/lakehanne/FARNN"> <b>Code (Github)</b> </a></p>


<hr/>
<h4><font color="#711E0C">Vision-based control of a soft-robot for Maskless Cancer Radiotherapy.</font></h4>
    <p><font color="#110D0C">An LQG-based controller for a soft-robot targeted towards accurate patient positioning systems in maskless head and neck cancer radiotherapy. With two RGB-D sensors in a multisensor kalman fusion scenario, we estimate the position of a patient during simulated maskless cancer RT in real-time. </font> <br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>.<font color="#110D0C"><i> IEEE Conference on Automation Science and Engineering (CASE).</i> Fort-Worth, Texas, August 2016. </font><br>
<i class="fa fa-file-pdf-o"></i> <a href="{{ media_url('Papers/CASE2016/CASE2016.pdf') }}" class="border"><b>PDF &nbsp;</b></a> 
<a href="https://arxiv.org/abs/1610.01481"><b> arXiv &nbsp;</b></a> 
<a href="https://github.com/SeRViCE-Lab/RAL-Codes"> <b>Code (Github)</b> &nbsp; </a> 
<a href="dfwslides/CASE2016.html"> <b> Slides</b></a>


<hr/>
<h4><font color="#711E0C">A Real-Time Soft-Robotic Patient Positioning System for Maskless Head-and-Neck Cancer Radiotherapy.</font></h4>
    <p><font color="#110D0C"> Use of inflatable air bladders in controlling the flexion/extension cranial motion of a simulated patient during maskless cancer radiotherapy. We imitate IGRT by using RGB-D depth sensors to generate surface images of a patient and extract the pose information from the reconstructed mesh. Results show that the system is capable of controlling head motion to within 2mm with respect to a reference trajectory. </font> <br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>.<font color="#110D0C"><i> IEEE Conference on Automation Science and Engineering (CASE).</i> Gothenburg, Sweden, August 2015. <br>
    </font>
  <a href="{{ media_url('Papers/CASE2015/CASE2015.pdf') }}" class="border"><b><i class="fa fa-file-pdf-o"></i> PDF &nbsp;</b></a> 
  <a href="https://arxiv.org/abs/1506.04787"><b> arXiv &nbsp;</b></a> 
  <a href="https://github.com/lakehanne/CASE_LabVIEW_Code"> <b>Code (Github)</b> &nbsp; </a> 
  <a href="dfwslides"> <b>Slides&nbsp;</b></a>
  <b>doi: 10.1109/CoASE.2015.7294318 </b>

  <hr/>
  <h4><font color="#711E0C">An Image-Guided Soft Robotic Patient Positioning System for Maskless Head-And-Neck Cancer Radiotherapy: A Proof-Of-Concept Study.</font></h4>
      <p><font color="#110D0C"> Use of inflatable air bladders in controlling the flexion/extension cranial motion of a simulated patient during maskless cancer radiotherapy. We imitate IGRT by using RGB-D depth sensors to generate surface images of a patient and extract the pose information from the reconstructed mesh. Results show that the system is capable of controlling head motion to within 2mm with respect to a reference trajectory. </font> <br>
      <font color="blue"><b>Olalekan Ogunmolu*</b>, Nick Gans, Steve Jiang, Xuejun Gu</font>.<font color="#110D0C"><i> American Association of Physicists in Medicine (AAPM) Annual Meeting.</i> Anaheim, CA, July 2015. <br>
      </font>
    <a href="http://www.aapm.org/meetings/2015AM/PRAbs.asp?mid=99&aid=29621" class="border"><b><i class="fa fa-file-pdf-o"></i> Abstract &nbsp;</b></a> 

<hr/>
<h4><font color="#711E0C">Autonomous Navigation of a Rotor-craft unmanned aerial vehicle
using machine vision.</font></h4>
    <p><font color="#110D0C"> Flying of the ACSE dept quadrotor using extracted image features from a structured indoor environment. We apply invariant moments, extract corners from UAV camera frames and
    compare results with calibrated helipad image; we learn actual helipad features by computing matching variance and then estimate the UAV pose in a hovering condition to plan landing.
</font> <br>
    <font color="blue"><b>Olalekan Ogunmolu.</b></font>.<font color="#110D0C"><i> MS Thesis. ACSE Dept, The University of Sheffield. </i> Sheffield, United Kingdom, August 2012. <br></font>
  <a href="http://lakehanne.github.io/downloads/MS_Thesis.pdf" class="border"><b><i class="fa fa-file-pdf-o"></i> PDF &nbsp;</b></a> 

<br></br>
<hr/>
<h3>Curriculum Vitae</h3>
<p><a href="{{ media_url('pdfs/CV.pdf') }}"><b> Academic CV (.pdf).<br></br>
	<small>Last updated: August, 2016</small></b></a>.</p>
<hr/>
