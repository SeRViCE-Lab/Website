---
extends: minimal.j2
default_block: main
title: Publications
description: Demos and Talks
---
<!-- Google Anakytics Tracker -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-64680332-3', 'auto');
  ga('send', 'pageview');
  ga('send', 'pageview' '/research.html');
  ga('send', 'pageview' '/speaking.html');
  ga('send', 'pageview'  '/projects.html');
  ga('send', 'pageview' 'http://lakehanne.github.io/');
  ga('send', 'pageview' '/dfwslides');

</script>

  
<html>

<h1>Publications</h1>
<hr/>
<h4><font color="#711E0C">A 3-DOF Neuro-Adaptive Pose Correction System For Frameless and Maskless Cancer Radiotherapy.</font></h4>
    <p><font color="#110D0C">Precise patient positioning during treatment of cancers of the head and neck region is essential for successful
clinical removal of malignant tumors. We propose a 3-DOF soft-robot head and neck position correcting mechanism, consisting of 3 independent inflatable air bladders that adaptivelymove patientâ€™s head with respect to set trajectory along 3-axes without sacrificing safety and comfort. An adaptive-neurocontroller consisting of a state feedback regulator, a commandreference tracking component, and a neural-network functionapproximator regulates the amount of actuation that each soft-robot experiences. Feedback is provided by a precise 3D stereocamera for surface imaging and pose measurement of the head.This paper is a trial of the correcting soft-actuation mechanismand neuro-adaptive controller on a 3D printed head-and-necksimulator. We demonstrate that our control exhibits real-timelearning and adaptive actuation that compensates for correctintrafractional patient positioning deviations.
 </font><br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Adwait Kulkarni, Yonas Tadesse, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>. 
    <!-- <font color="#110D0C">arXiv Preprint <i>arXiv:1703.03821</i>. </font>  -->
    <br>
    <!-- <a href="{{ media_url('Papers/IROS2017/IROS2017.pdf') }}" class="border"><i class="fa fa-file-pdf-o"></i><b>PDF &nbsp;</b></a>  -->
    <!-- <a href="https://arxiv.org/abs/1610.01439"><b> arXiv &nbsp;</b></a>  -->
    <!-- <a href="https://github.com/lakehanne/FARNN"> <b>Code (Github)&nbsp;</b> </a> -->
    <!-- <a href="http://lakehanne.github.io/Deep-Nets-Identification"> <b>Blog &nbsp;</b> </a> -->
  </p>

<h4><font color="#711E0C">Nonlinear Systems Identification Using Deep Dynamic Neural Networks.</font></h4>
    <p><font color="#110D0C">An investigation of the effectiveness of deep neural networks in the modeling of dynamical systems with complex behavior. Three deep neural network structures are trained on sequential data, and we investigate the effectiveness of these networks in modeling associated characteristics of the underlying dynamical systems. </font><br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>. <font color="#110D0C">To appear in <i>American Control Conference (ACC)</i>. Seattle, WA. May 2017.</font> <br>
    <a href="{{ media_url('Papers/ACC2016/ACC2016.pdf') }}" class="border"><i class="fa fa-file-pdf-o"></i><b>PDF &nbsp;</b></a> 
    <a href="https://arxiv.org/abs/1610.01439"><b> arXiv &nbsp;</b></a> 
    <a href="https://github.com/lakehanne/FARNN"> <b>Code (Github)&nbsp;</b> </a>
    <a href="http://lakehanne.github.io/Deep-Nets-Identification"> <b>Blog &nbsp;</b> </a>
  </p>


<hr/>
<h4><font color="#711E0C">Vision-based control of a soft-robot for Maskless Cancer Radiotherapy.</font></h4>
    <p><font color="#110D0C">An LQG-based controller for a soft-robot targeted towards accurate patient positioning systems in maskless head and neck cancer radiotherapy. With two RGB-D sensors in a multisensor kalman fusion scenario, we estimate the position of a patient during simulated maskless cancer RT in real-time. </font> <br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>.<font color="#110D0C"><i> IEEE Conference on Automation Science and Engineering (CASE).</i> Fort-Worth, Texas, August 2016. </font><br>
<i class="fa fa-file-pdf-o"></i> <a href="{{ media_url('Papers/CASE2016/CASE2016.pdf') }}" class="border"><b>PDF &nbsp;</b></a> 
<a href="https://arxiv.org/abs/1610.01481"><b> arXiv &nbsp;</b></a> 
<a href="https://github.com/SeRViCE-Lab/RAL-Codes"> <b>Code (Github)</b> &nbsp; </a> 
<a href="dfwslides/CASE2016.html"> <b> Slides</b></a>


<hr/>
<h4><font color="#711E0C">A Real-Time Soft-Robotic Patient Positioning System for Maskless Head-and-Neck Cancer Radiotherapy.</font></h4>
    <p><font color="#110D0C"> Use of inflatable air bladders in controlling the flexion/extension cranial motion of a simulated patient during maskless cancer radiotherapy. We imitate IGRT by using RGB-D depth sensors to generate surface images of a patient and extract the pose information from the reconstructed mesh. Results show that the system is capable of controlling head motion to within 2mm with respect to a reference trajectory. </font> <br>
    <font color="blue"><b>Olalekan Ogunmolu*</b>, Xuejun Gu, Steve Jiang, and Nicholas Gans</font>.<font color="#110D0C"><i> IEEE Conference on Automation Science and Engineering (CASE).</i> Gothenburg, Sweden, August 2015. <br>
    </font>
  <a href="{{ media_url('Papers/CASE2015/CASE2015.pdf') }}" class="border"><b><i class="fa fa-file-pdf-o"></i> PDF &nbsp;</b></a> 
  <a href="https://arxiv.org/abs/1506.04787"><b> arXiv &nbsp;</b></a> 
  <a href="https://github.com/lakehanne/CASE_LabVIEW_Code"> <b>Code (Github)</b> &nbsp; </a> 
  <a href="dfwslides"> <b>Slides&nbsp;</b></a>
  <b>doi: 10.1109/CoASE.2015.7294318 </b>

  <hr/>
  <h4><font color="#711E0C">An Image-Guided Soft Robotic Patient Positioning System for Maskless Head-And-Neck Cancer Radiotherapy: A Proof-Of-Concept Study.</font></h4>
      <p><font color="#110D0C"> Use of inflatable air bladders in controlling the flexion/extension cranial motion of a simulated patient during maskless cancer radiotherapy. We imitate IGRT by using RGB-D depth sensors to generate surface images of a patient and extract the pose information from the reconstructed mesh. Results show that the system is capable of controlling head motion to within 2mm with respect to a reference trajectory. </font> <br>
      <font color="blue"><b>Olalekan Ogunmolu*</b>, Nick Gans, Steve Jiang, Xuejun Gu</font>.<font color="#110D0C"><i> American Association of Physicists in Medicine (AAPM) Annual Meeting.</i> Anaheim, CA, July 2015. <br>
      </font>
    <a href="http://www.aapm.org/meetings/2015AM/PRAbs.asp?mid=99&aid=29621" class="border"><b><i class="fa fa-file-pdf-o"></i> Abstract &nbsp;</b></a> 

<hr/>
<h4><font color="#711E0C">Autonomous Navigation of a Rotor-craft unmanned aerial vehicle
using machine vision.</font></h4>
    <p><font color="#110D0C"> Flying of the ACSE dept quadrotor using extracted image features from a structured indoor environment. We apply invariant moments, extract corners from UAV camera frames and
    compare results with calibrated helipad image; we learn actual helipad features by computing matching variance and then estimate the UAV pose in a hovering condition to plan landing.
</font> <br>
    <font color="blue"><b>Olalekan Ogunmolu.</b></font>.<font color="#110D0C"><i> MS Thesis. ACSE Dept, The University of Sheffield. </i> Sheffield, United Kingdom, August 2012. <br></font>
  <a href="http://lakehanne.github.io/downloads/MS_Thesis.pdf" class="border"><b><i class="fa fa-file-pdf-o"></i> PDF &nbsp;</b></a> 

<br></br>
<hr/>
<h3>Curriculum Vitae</h3>
<p><a href="{{ media_url('pdfs/CV.pdf') }}"><b> Academic CV (.pdf).<br></br>
	<small>Last updated: December, 2016</small></b></a>.</p>
<hr/>

<br/>
<h3>Concise Resume</h3>
<p><a href="{{ media_url('pdfs/Concise_CV.pdf') }}"><b> Resume (.pdf).<br></br>
  <small>Last updated: December, 2016</small></b></a>.</p>
<hr/>
