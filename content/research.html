---
extends: minimal.j2
default_block: main
title: Research
description: Description of Past and Current Research Interests
---
<!-- Google Anakytics Tracker -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-64680332-3', 'auto');
  ga('send', 'pageview');

</script>
  
<h1>Research</h1>
<hr/>
<h2>Background</h2>
<p>After completing my undergraduate studies in Physics, I took a few years off before returning to academia. In those years I worked in a mobile Telco firm in Nigeria and later relocated to Lagos as a Supply-Chain manager for Coke's second-largest warehouse in Nigeria. Those four years in communications technology and business management left me with a rekindled interest in science and technology, and control systems in particular.</p>

<p>I love tinkering with machines, marveling at the interconnectedness of components which enables hardware to function as envisioned. I had my Master's degree in Control Systems at the  <a href="http://www.sheffield.ac.uk/">University of Sheffield's</a> <a href="http://www.sheffield.ac.uk/acse"> Automatic Control and Systems Engineering (ACSE) department.</a> There, I started combining scientific elegance with practical impact and I worked with <a href="https://www.sheffield.ac.uk/acse/staff/tjd">Tony Dodd</a> during my Thesis. I started my doctoral studies at UT Dallas in Fall of 2014. When not working in the lab, I enjoy spending time with my family, cycling in the country, or swimming.</p>

<h2>Research Interests</h2>
I started my PhD with a vague interest in cancer radiotherapy, and a hope to understand deep nets in detail; finding aplications of it to system identification of complex nonlinear dynamical systems and robots learning and cognition. I find Professor Gans to be very flexible in the way he allows his students to develop the skills they feel might be important for their career.
<hr/>

<ul>

<li><b>Head-and-Neck Patient Motion Control in Cancer Radiotherapy.</b><br>
Shortly after the start of my studies in Dr. Gans' lab, we began investigating ways of automating the otherwise expensive state-of-the-art process of controlling a patient's head and neck motion during cancer radiotherapy so as to minimize the exposure of organs at risk to excessive radiation as well as automate the calibration process (usually by a medical physicist) of a patient's optimal placement on a 6-D robotic couch to move the patient as desired based on an hyper-sensitive image-guidance system during RT. 
<p>Our conclusion, along with <a href="http://profiles.utsouthwestern.edu/profile/150563/steve-jiang.html">Steve Jiang</a> and <a href="http://profiles.utsouthwestern.edu/profile/133029/xuejun-gu.html"> Xuejun Gu</a>, from state-of-the art in literature, was that existing methods still produced a lot of discomfort for the patient and though while achieving desired accuracy with optical guidance systems, it causes a lot of pain to the patient and takes a long time to properly calibrate a patient's position accurately.</p> We came up with deformable soft-robots that can actuate based on feedback from a visual sensor in a simulated scenario and this is discussed at length in our <a href="http://arxiv.org/abs/1506.04787v2"><b>CASE paper</b></a>.
</li>
<hr/>

<br></br>
<li><b>Visual-Servoing Control of a Soft-Robot</b><br>
How do you actively cancel noise from a generic low-cost vision sensor (e.g. Kinect) and infer real-world pose accurately? This past summer, I developed a visual perception scheme, using multiple RGB-D cameras, based on the robot operating system (ROS) in order to reduce uncertainty/jitter in the pose-estimation of an object using classical AI methods, and while parallelizing the AI algorithm on multiple GPU cores with CUDA C++ and OpenCV API. I mounted the cameras across a simulated patient's face, tracked local eye features in real-time (from each camera) using Haar basis-like functions, and performed recursive discrete estimation of each sensor's observation locally. Each local estimate was fused at a central site with a probabilistic scheme that weighted the variance from each sensor's observation in order to construct a more reliable result. The result improved pose accuracy markedly compared to using raw observations from RGB-D sensors. While not reaching clinical set-up ideals for our envisioned RT requirement, it achieved a significantly better sub-millimeter accuracy over our previous results. I continue to explore better means of reaching accuracy cheaply on my model throughout this Fall term while simultaneously modeling the soft robot system that positions a patient automatically based on observed deviations from setpoint. <!-- My ultimate goal is to eliminate the danger patients face (such as brain necrosis and exposure of organs at risk to dangerous radiation) in current head and neck (H\&N) cancer RT state-of-the-art. I am also investigating the use of convoluted networks in medical imaging. --> This work, in final form, will be submitted to the journal of Robotics and Automation Letters in soon for review. <i><b>Watch this space!</b></i><hr/>
</li></b>

</ul>

<h2>Current</h2>

<hr/>
<li><b>Identification of complex nonlinear dynamical systems using neural nets</b><br>
Are you a control systems theorist who is awed by the <a href="http://lakehanne.github.io/neuraltalk/">unreasonable effectiveness of deep neural networks</a>? In the 1950's, control theorists introduced neural network models for use in control theory and especially in system identification. Since neural networks could not be used directly in time-varying systems, people sort of abandoned this line of research. Instead, we developed mathematical schemes through the decades such as stability and instability in switched systems and adaptation in rapidly time-varying environments as well as modeling and control of decentralized autonomous agents to cope with time-varying nonlinear phenomenon. But since AlexNet smashed the world cup of computer vision in 2012, the computer vision community has been reinvigorated in using ConvNets (convolutional neural networks) introduced by <a href="http://yann.lecun.com/">Yann Lecun</a> in the 90's on GPUs and they have truly achieved remarkable performance. 

<p>Because the dataset we mostly work with in classical system identification are not rich (or shall I say big) enough, a lot of control theorists have not caught up with the hype in pop culture (:D) and in academic instutions around the country when it comes to harvesting the power of convnets/RNNs to accurately reproduce complex nonlinear real-world systems. I am on an investigative quest to adapt this magical algorithms to complex dynamical control problems, analyze their effectiveness and hopefully inspire a new generation of engineers to seize the day and use deep nets in identification, and control/accurate simulation of large-scale models. <b><i>Come on with me!</i></b>
</p>
</li></b>
<hr/>

<li><b>Amazon Internship</b><br>
Next spring and summer, I will be in <b>Amazon Robotics LLC</b> as a <b>Mechatronics Intern</b> in the Boston area. In this role, I will have the opportunity to collaborate with colleagues in many areas of research including deep learning for object recognition/natural language processing, as well as nonlinear control of complex dynamical systems. More details coming soon.
</li>