<!doctype html>
<html lang="en">
<!-- Mathjax script -->
	<head>
		<script type="text/x-mathjax-config">
				MathJax.Hub.Config({
					  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
				});
		</script>

		<script type="text/javascript" src="MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
		</script>

		<meta charset="utf-8">

		<title>A 3-DoF Neuro-Adaptive Patient Pose Correcting System for Frameless and Maskless Cancer Radiotherapy</title>

		<meta name="description" content="A case for automating head and neck cancer radiotherapy treatment">
		<meta name="author" content="Olalekan Ogunmolu">

		<meta name="apple-mobile-web-app-capable" content="yes">
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/league.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/serif.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-background="images/CASE2016/novalis.jpg" style="display:block; background:#000; opacity: 0.56" slide-background="#000">
					<h4>A 3-DoF Neuro-Adaptive Patient Pose Correcting System for Frameless and Maskless Cancer Radiotherapy</h4><br>
					<p><font size="5" color="yellow">Towards Precise Patient Positioning during Head and Neck Cancer Radiotherapy</font></p><br>
					<p>
						<small><a href="http://ecs.utdallas.edu/~olalekan.ogunmolu">Olalekan Ogunmolu</a> | 03.24.2017</a></small><br></br>

						<small>
						<a href="http://ecs.utdallas.edu/~olalekan.ogunmolu">Collaborators: A. Kulkarni, </a> 
						<a href="http://me.utdallas.edu/people/tadesse.html"> Y. Tadesse, </a>
						<a href="http://profiles.utsouthwestern.edu/profile/133029/xuejun-gu.html">X. Gu </a>, <a href="https://profiles.utsouthwestern.edu/profile/150563/steve-jiang.html">S. Jiang, and </a>
						<a href="http://ecs.utdallas.edu/~ngans"> N. Gans</a>
						</small><br>
				
						<small>
						Department of Electrical Engineering, UT Dallas <br>
						Department of Mechanical Engineering, UT Dallas<br>
						Department of Radiation Oncology, UT SouthWestern
					</small></a><br></br>
					</p>
				</section>

				<section data-transition="slide" data-background="#4d7e65" data-background-transition="zoom">
					<section data-background="images/HNCancerRegions.png" style="display:block;background:#000;opacity:0.75;">
						<h2>Background</h2>
						<p>Head and neck (H&N) cancers are among the most fatal of major cancers in the United States</p>					
						<br>
						<p>2014: 35% of all pharynx and oral cavity cancers developed led to fatility [Siegal, R. et. al]</p>
						<br>
						<p>Cancer kills almost ~600,000 people each year in the U.S. alone. <br><a href="https://www.cancer.gov/about-cancer/understanding/statistics"><small><br>Source: U.S. National Cancer Institute .</small></a></p>
						<a href="#" class="navigate-down">
							<img width="78" height="138" data-src="https://s3.amazonaws.com/hakim-static/reveal-js/arrow.png" alt="Down arrow" style="display:block;background:#000;opacity:0;">
						</a>
						<br>
					</section>	

					<section data-background="images/UTSW2017/igrt_setup.jpg" style="display:block;background:#000;opacity:0.75;">
						<p><font color="#DAF7A6" face="verdana" size="25">Radiation-based Treatment Procedures</font></p>	
						<p>Could be IMRT and/or IGRT</p>					
						<table border="5", width="80%">
							<thead>
								<tr>
									<th><font color="#DAF7A6" size="6"><center>IMRT: Intensity Modulated Radiotherapy</center></font></th>
								</tr>
							</thead>
							<tbody>
								<tr>
									<td>
										<small><li type="square">Modulates dosage/shape of radiation beam <u>to precise size of tumor cells
										</li></small>
										<small><li type="square">Improves accuracy of <u>carefully</u> targeted radiation </li></small>
									</td>
								</tr>
								<th><font color="#DAF7A6" size="6"><center>IGRT: Image Guidance Radiation Therapy</center></font></th>
								<tr>									
									<td>							
										<!--<small><li type="square">Uncertainty in  dose measures to malignant tissues necessitated use of IGRT</li></small> -->
										<small><li type="square">Goal: Assure precise localization of beam to target tumor cell. 
										</li></small>
								<!-- <ul>										
									<img src="images/UTSW2017/igrt_setup.jpg" align="right" width="35%" height="50%"/>
								</ul> -->
									</td>
								</tr>
							</tbody>
						</table>
						<aside class="notes">
							<h3>Radiation Therapy</h3>
							<small><li type="square">Good procedure for distributed cancer cells</li></small>
							<small><li type="square">Palliative treatment when tumors elimination is impossible</li></small>
							<small><li type="square">Shrinks cancer tumors pre-surgery  or tumor leftovers post-surgery</li></small>
							<li><small>
								While conventional RT uses rigid immobilization techniques such as masks, frames, arm positioning devices or vacuum mattresses [1], IGRT methods employ ultrasound, 3D imaging systems, 2D X-ray devices and/or computed tomography to instantly amend positioning errors, and to improve daily radiotherapy fractionsâ€™ precision.
							</small></li>
						</aside>
					</section>	
				</section>

				<section>					
					<section data-background="images/UTSW2017/igrt_setup.jpg" style="display:block;background:#000;opacity:0.75;">	
						<h3>The case for accurate patient positioning</h3>
						<ul>
							<li>Modern irradiation procedures allow dose errors of a few millimeters
								<ul>									
									<li>This informs computer calculation of highly precise radiation treatment plans on static planning images</li>
								</ul>
							</li>							
							<li>But static CT scans are unrealistic during real-time patient treatment
								<ul>
									<li>How to minimize/eliminate <u>intrafractional variations</u> during treatment?</li>
								</ul>
								</li>
						</ul>
						<aside class="notes" data-markdown>
							**Various interfractional gradients**
							- patient poisitioning, 
								- Accuracy and reproducibility of positioning strongly correlated to anatomic region involved
								- Also correlated to positioning aids used

							- organ mobility, and 

							- anatomic variations during treatment. 
						</aside>
					</section>

					<section data-background="images/UTSW2017/igrt_pose_error.jpg" style="display:block;background:#000;opacity:0.75;" >	
						<h3>Setup and Session Errors </h3>
						
						<ul>
							<li>Patient Positioning
								<ul>
									<small><li>Precise positioning means use of rigid fixators for patient immobilization</li></small>
									<small><li>Downside: Patient comfort jeopardized; requires surface markings; assumes organs are rigid </li></small>
								</ul></li>

							<li>Internal Organ Mobility 
								<ul>
									<small><li>Perfect positioning of skeletal structures $\neq$ Organ immobility
									</li></small>
									<small><li>e.g. ventral displacement or geographic miss from moving organs
									</li></small>
								</ul></li>

							<li>Anatomic variations during treatment.
<!-- 								<ul>
									<small><li>Changing tumor density during treatment $\rightarrow$ tissue attenuation of beams</li></small>
									<small><li>Weight loss, or inflammatory reaction in the course of treatment could reduce attenuation of X-ray beam or expose neighboring entity</li></small>
								</ul> -->
							</li>

						</ul>



						<aside class="notes" data-markdown>
							**Various interfractional gradients**
							- patient positioning, 
								- Accuracy and reproducibility of positioning strongly correlated to anatomic region involved
								- positioning aids used to esure accuracy include masks, shoulder fixators, vacuum mattresses or arm positioning devices
								
								**Disadvantages**
								- These methods depend on surface markings
								- But actual position of body parts can change considerably e.g. lung tumors etc

								**Fix**
								- Use IGRT to detect and correct these deviations --> increases precision of delivery e.g.
									** Utilities **
									- Modern high-precision techniques with individual dose distribution
									- Escalate dose in target volume 
									- spare adjacent radiosensitive organs

							- organ mobility, 
								- Perfect positioning of skeletal structures != Organ immobility e.g.
									- Ventral displacement can result in renal damage in RT of para-aortic lymph nodes 
									- Treatment of thorax cancer can result in geographic miss due to the high variations in esophagus position (F. Sterzing: IGRT)

									**Fix**
									- IGRT can recognize displacements well ahead of time so that treatment is carried out under better conditions.

							- anatomic variations during treatment. 
								- Changing tumor density during treatment could affect tissue attenuation of beams
									- Weight loss in the course of treatment may shift tumor location exposing skin and salivary glands to treatment toxicity
									- imaging procedure can be used to calculate dosage distribution --> Goal: modify irradiation plan; optimal treatment over several weeks
									- Shrinking lymphomas may shrink after treatment commencement
						</aside>
					</section>

					<section  >
					<!-- data-background="images/UTSW2017/igrt_setup.jpg" style="display:block;background:#000;opacity:0.75;" -->	
						<h3>Limitations of existing solutions</h3>
						<ul>

							<ul>
								<img src="images/UTSW2017/frame-based.jpg" align="right" width="25%", height="30%" alt=""/>
							</ul>
							<li>Frame-based immobilization systems are highly uncomfortable [Lutz, W. et. al, 1988], Takakura, T., et al., 2010]
							</li><br>

							<li>Involuntary patient movements is not a boon for  inspection-based setups  [Cervino, L.I. et. al., 2010, Li G. et al, 2015] </li><br>

							<ul>
								<img src="images/UTSW2017/4-dof.jpg" align="right" width="20%", height="20%" alt=""/>
							</ul>

							<li>Existing real-time correcting proposal employs stepper motors for head motion alignment[Li, X. et al, 2015]
							</li>
						</ul>

						<aside class="notes" data-markdown>
							### Research Motivation

							- 	Evidence of treatment discomfort and severe pain from long hours of minimally invasive surgery <font color="#8A2BE2">[Takakura, T., et al., 2010]</font>

							- 	Frame-based: Lack of comfort, limited repeatability and clinically inefficient 

							-	Patient movements: Clinical studies show that small perturbations cause high sensitivity to IMRT treatment dose <font color="#8A2BE2">[L. Xing, 2000.]</font>
							</a>

							-	6DOF positioning systems model the human body rigidly 

							-	No accounting for flexibility/curvature of the neck
							
							-	Limited positioning of patient can reduce effectiveness of treatment
						</aside>
					</section>
			</section>

			<section>

				<section data-background="images/UTSW2017/igrt_setup.jpg" style="display:block;background:#000;opacity:0.75;" >	
					<h3>Solution: Soft Position Correcting Systems</h3>
					<ul>							
						<li>Eliminate rigid frames and metallic rings used in immobilization that make patient uncomfortable &#10004; </li><br>
						<!-- <li>Current frameless SRS techniques have little or no real-time correction</li> -->
						<li>Eliminate attenuation of X-Ray beams &#10004; </li><br>

						<li>Remove need to constantly model nonlinear dynamics of patient's torso region and soft robotic actuators &#10004; </li><br>
						
						<li>Ensure control system is robust to (non)-parametric uncertainties &#10004; </li><br>
					</ul>

					<aside class="notes">
						<ul>
							<li>
								Instead of uncomfortable rigid frames $\rightarrow$ use soft-robot actuators
								<ul>
									<li>i.e. radiation transparent elastomeric and pneumatic actuation systems </li>
								</ul>
							</li>

							<li>
								Instead of strictly mechanical stepper motors that attenuate X-ray beams, use pneumatic valves separated from patient head and neck + robotic couch system and use silicone/rubber air-hoses to convey air into actuating mechanisms
							</li>

							<li>
								Instead of a feedback controller, why not an adaptive controller?
								<ul>
									<li><small>$i.e.$ With the indirect method, adaptively compensate for the changing shape and anatomy of patient's head and neck dynamics</li></small>
								</ul></li>
							</li>

							<li>Make adaptation robust to non-parametric uncertainties? $\rightarrow$ How about a real-time function approximator-based adaptive controller?</li>
						</ul>
					</aside>
				</section>

				<section data-background="#566573" >
					<h5>Testbed</h5>
					<img src="images/UTSW2017/setup.jpg" width="755px" height="465px"/>
					<!-- <img src="images/UTSW2017/headnaxes.jpg" width="400px" height="210px"/> -->

					<aside class="notes" data-markdown>
						
						-	3 custom-designed inflatable air bladders positioned beneath a custom-designed 3D head and 	neck simulator

						-	Rubber Air hoses convey air into/out of each IAB

						- 	Air is supplied from a pressure cannister through air regulating Dakota valves 

						- 	Surface image of head is reconstructed witrh an Ensenso 3D camera, mounted above the head

					</aside>
				</section>
			</section>

			<section>

				<section data-background="#212F3C" data-background-transition="zoom">	
					<h3> Vision-based Pose Estimation Steps</h3>

					<ul>
						<small><li>Find edges of 2D planar regions in scene structure [Torr and Zisserman, 2000]</small>
							<ul>
								<small><li>
							$\rightarrow$ bound resulting plane indices with their 2D convex hull
						</li></small>
						<img src="images/UTSW2017/faceCluttered.jpg" align="right" width="25%", height="40%" alt="" />
						</ul> 
						</li>

						<small><li>Extract face and face-height neighbors into a predefined 2D prismatic model [Rusu, R. et. al, 2008]</li></small><br></br>

						<small><li>Cluster extracted points based on a Euclidean Clustering scheme defined in the paper</li></small><br>

						<small><li>Face will be the largest cluster</li></small>

					</ul>

					<aside class="notes">
						<ul>
							<li>Minimize sensor noise by downsampling point cloud with the robust moving least squares algorithm (RMLS) [Rusu, R. et al, 2008] </li>

							<li>Search for edges using maximum likelihood SAC [Torr and Zisserman, 2000]</li>

							<li>
								Polygonal model is based on a user-defined $L_1$ Manhattan distance [Rusu, R. et. al, 2008]
							</li>
						</ul>

					</aside>
				</section>

				<section data-background="#212F3C" data-background-transition="fade">
					<h3>Segmentation Results</h3>
					<img src="images/UTSW2017/seg_cloud_nice.jpg" alt="" width="65%", height="65%"/>

					<aside class="notes">
						<p><small>[Top-left]: Dense point cloud of the experimental setup scene.
						[Top right]: Downsampled cluttered cloud of the left scene. [Bottom-left]:
						Using RANSAC, we searched for 2D plane candidates in the scene and
						compute the convex hull of found planar regions. We then extrude point
						indices within the hull into a prismatic polygonal model to give the face
						region. [Bottom-right]: An additional step clusters the resultant cloud based
						on a Euclidean distance. The largest cluster is taken to be the face.
						</small></p>					
					</aside>
				</section>
			</section>

			<section> <!-- Control Background-->
				<section data-background="#212F3C" data-background-transition="zoom">
					<h3>Control Design Objectives</h3>
					<ul>
						<li>Stabilize system states</li><br>

						<li>Optimal closed loop tracking given a desired trajectory</li><br>

						<li>Robustify system to (non-)parametric uncertainties 
							<ul>
								<small><li>$\rightarrow$ changing head shapes, size and other anatomic/tumor variations</li></small>
							</ul></li>

					</ul>
					
					<aside class="notes">
						<ul>
							<li>Optimal tracking problem: Design a feedback regulator component</li>
							<li>Stability of states: Design a state feedback controller with adaptive gains for states we desire to tame</li>
							<li>Non-parametric Uncertainties: Adaptive control in a Bayesian setting 
								<ul>
									<small><li>$\rightarrow$ given an intial distributtion, minimize a well-chosen cost function as the expected value of the head pose 
								given the system's states and past control actions</small></li>
								<small><li>$\rightarrow$ essentially a neural network function approximator that models the system nonlinearity $f(\mathbb{y})$</small>
								</ul></li> 
						</ul>

					</aside>
				</section>

				<section data-background="#212F3C" data-background-transition="zoom">
					<h3>Model Reference Adaptive System (MRAS) Design</h3>
					<ul>
						<small><li>Model head and bladder dynamics as <br>
							&nbsp; &nbsp; &nbsp; $\dot{\textbf{y}} = \textbf{A}\textbf{y} + \textbf{B} {\Lambda} \left(\textbf{u} - f(\textbf{x}) \right) + \textbf{w}(k) $ , <br>
							
							&nbsp; &nbsp; &nbsp; <small>where $f(\textbf{x})$ is a nonlinear function to be  adapted for in our controller parameters<br>
							&nbsp; &nbsp; &nbsp; and $\textbf{x}$ is the tuple containing past controls and current outputs </small></li></small><br></br>

						<small><li>	Approximate $f(\textbf{x})$ by a neural network with continuous memory states  <br> 

							&nbsp; &nbsp; &nbsp; $\hat{f}\left(\textbf{u}(k-d), \textbf{y}(k),\textbf{w}(k)\right)$ 
						<ul><small>
							<li>$\rightarrow$ $\hat{f}(\cdot)$ is realized with a Long-Short Term Memory Cell  &nbsp; [Horchreiter and Schmidhuber, 1991, 1997]</li>
							<li><u>Purpose:</u> Remember good adaptation gains</li>
						</small>
						</ul>
						</li></small><br></br>

						<small><li>Set up control law in terms of parameter estimates from the neural network weights and Lipschitz basis functions, $\Phi(\textbf{y}) = \{\textbf{y}(k-d), \cdots, \textbf{y}(k-d-4), \textbf{u}(k-d) \cdots \textbf{u}(k-d-5)\}$<br>
							<ul>
							<small><li>
								$i.e.$ network looks back in time by 5 time steps at every instant, and then makes a prediction 
							</li></small>
							</ul>

						</li></small><br></br>

						<small><li>Derive Adaptive Adjustment mechanism from Lyapunov analysis [Parks, P., 1966]</li></small>
					</ul>

					<aside class="notes" data-markdown>
						### Plant Dynamics

						-	with $\textbf{y} \in R^n, \textbf{u}\in R^m; \textbf{A} \in R^{n \times n}, \Lambda \in R^{m \times m}$
						being unknown constant matrices, $\textbf{B} \in R^{n \times m} \,	, sgn(\Lambda)$, being known constant matrices, and $\textbf{w}(k) \in R^n$ being a bounded time-varying unknown disturbance, upper-bounded by a fixed positive scalar $\textbf{w}_{max}$

						- we would like the adaptation scheme to have memory (i.e. memorize good values of parameters found); alternatively,

						### Why an LSTM?

						-	Capacity for long-term context memorization due to inherent multiplicative units and cell gates 

						-	avoids inherent RNN oscillating weights or vanishing gradients problem

						- 	Input-output data in our setup is a temporally evolving data

						-	Contribution of our work involves shaping the last layer to produce torque signals that actuate each of the six valves based on adaptation signals
					</aside>
				</section>

				<section data-background="#212F3C" data-background-transition="zoom">
					<h3>Assumptions</h3>
					<ul>
						<small><li> a dynamic RNN with $N$ neurons, $\varphi(\textbf{x})$, exists that will map from a compact input space $\textbf{u} \subset \mathbb{U}$ to an output space $\textbf{y} \subset \mathbb{Y}$ on the Lebesgue integrable functions with closed interval $[0, T]$ or open-ended interval $[0,\infty)$; </li></small><br></br>
							
						<small><li> the nonlinear function $f(\textbf{x})$ is exactly $\Theta^T \Phi(\textbf{x})$ with coefficients $\Theta \in R^{N\times m}$ and a Lipschitz-continuous vector of basis functions $\Phi(\textbf{x}) \in R^N$;</li></small><br></br>
						
						<small><li> inside a ball $\textbf{Y}_R$ of known, finite radius $R$, the ideal neural network (NN) approximation $f(\textbf{x}): R^n \rightarrow R^m$, is realized to a sufficient degree of accuracy, $\varepsilon_f > 0$;</li></small><br></br>
						<!-- 
						<small><li> the process noise $\textbf{w}(k)$ is estimated alongside model parameters by the dynamic recurrent NN (RNN) and lumped into $\varepsilon_f$; </li></small><br></br> -->

						<small><li> outside $\textbf{Y}_R$, the NN approximation error can be upper-bounded by a known unbounded, scalar function $\varepsilon_{max}(\textbf{x})$;							
						$\|\varepsilon(\textbf{x})\| \le \varepsilon_{max}(\textbf{x}), \quad \, \forall \quad \textbf{x} \in \textbf{Y}_R$;</li></small><br></br>
						
						<small><li> there exists an exponentially stable reference model 
						$\dot{\textbf{y}}_m = \textbf{A}_my_m + \textbf{B}_m \textbf{r}$</li></small>
						</li>
					</ul>

					<aside class="notes" data-markdown>
						### Design Parameters 

						- In a highly nonlinear setting as this, we settle for approximations rather than exact representation


						- we assume the relationship between input and output signals is a Borel measurable set
							- Borel set is any set in a topological space that can be formed from open sets (or, equivalently, from closed sets) through the operations of countable union, countable intersection, and relative complement.

						-	**say bullet 1 before saying next point**

						- 	The recurrent network is formed from compositions and superpositions of simple tanh and sigmoidal response functions

						-	with a Hurwitz matrix $\textbf{A}_m \in R^{n \times n} \text{ and } \textbf{B}_m \in R^{n \times m}$ commanded by a reference signal $\textbf{r} \in R^{m}$.

						- 	Afterall, a carefully designed neural system should be able to discriminate to arbitrary precision any collection of compact disjoint subsets of $\mathbb{R}^n$

						- 	Approximation property builds on Hornik, Cybenko, Funahashi works

						-	design an adaptive MRAC able to operate in the presence of parametric, $\varepsilon_f$, and non-parametric, $\textbf{w}(k)$, uncertainties so as to assure the boundedness of all signals within the closed-loop dynamics. 

					</aside>
				</section>
			</section>

			<section>
				<section data-background="#212F3C" data-background-transition="zoom">
					<h3>Controller Formulation</h3>
					<ul>
						<small><li>
							$\textbf{u} = \underbrace{\hat{\textbf{K}}_y^{\textbf{T}}\textbf{y}}_{\text{state feedback}} + \underbrace{\hat{\textbf{K}}_r^{\textbf{T}} \textbf{r}}_{\text{optimal regulator}} + \underbrace{\hat{f}(\textbf{x})}_{\text{nonlinearity RNN approximator}}$
							</li></small><br></br>

						<small><li>$\hat{\textbf{K}}_y \, \text{ and } \hat{\textbf{K}}_r$ are adaptive gains to be suitably designed</li></small><br>

						<small><li> There are model matching conditions such that $\hat{\textbf{K}}_y = \textbf{K}_y , \, \text{ and } \hat{\textbf{K}}_r = \textbf{K}_r$ (ideally)</li></small><br>

						<small><li>Mathematically, we can imagine the approximator as $\hat{f}(\textbf{x}) = \hat{{\Theta}}^T {\Phi}(\textbf{x}) + \varepsilon_f(\textbf{x})$
							<ul>
								<li>
									$\hat{\Theta}^T$ denotes the vectorized weights of the neural network and $\Phi(\textbf{x})$ denotes the vector of lagged inputs and output, $\varepsilon_f(\textbf{x})$ is the approximation error.
								</li>
							</ul>
						</li></small>
					</ul>

					<aside class="notes" data-markdown>
						-	$\hat{\textbf{K}}_y^{\textbf{T}}\textbf{y} $ term keeps the states of the approximation set  $\textbf{y} \in \textbf{Y}_R$ stable, while the $\textbf{K}_r^{\textbf{T}} \textbf{r}$ term causes the states to follow a given reference trajectory.  The function approximator output $\hat{f}(\textbf{y})$ ensures states that start outside the approximation set $\textbf{y} \in \textbf{Y}_R$ converge to $\textbf{Y}_R$ in finite time (it converges non-parametric errors $\varepsilon_f$ that puts certain states out of the approximation set into $\textbf{Y}_R$).

						-	where $\hat{\Theta}^T$ denotes the vectorized weights of the neural network and $\Phi(\textbf{y})$ denotes the vector of lagged inputs and output defined as
							${\Phi}(\textbf{y}) = \{\state(k-d) &\cdots \state(k-d-4), \nonumber\\	&\textbf{u}(k-d) \cdots \textbf{u}(k-d-5)\}$
							and	$\neterror(\textbf{y})$ is the approximation error.
					</aside>
				</section>

				<section data-background="#212F3C" data-background-transition="zoom">
					<h4>Recurrent Neural Network Model</h4>
					<img src="images/UTSW2017/lstm.jpg" alt="" height="80%" width = "70%"/>

					<aside class="notes" data-markdown>

						###  Adaptation Memory System

						-	The approximator will have the effect that the values of the adjustable parameters at time $t$ will depend not only on $e(t)$ will depend not only $e(t)$ but also on its past values: $e(\tau) \, \tau \le t$, 

					</aside>

				</section>

				<section data-background="#212F3C" data-background-transition="zoom">
					<h4>Closed Loop Dynamics</h4>
					<ul>
						<small><li>State closed loop dynamics is given by <br>
							&nbsp; &nbsp; $\dot{\textbf{y}} =  \textbf{A} + \textbf{B} \Lambda (\hat{\textbf{K}}_{y}^{T} \textbf{y} + \textbf{B} \Lambda (\hat{\textbf{K}}_r^T \textbf{r} + \varepsilon_f))$
							<ul>
								where $\textbf{A}$ and $\Lambda$ are unknown matrices. The sign of $\Lambda$ is known. $\hat{\textbf{K}}_{y}^{T} \text{ and } \hat{\textbf{K}}_r^T$ are adaptation gains to be determined.
							</ul>
						</li></small><br></br>

						<small><li>The generalized error state vector $\textbf{e}(k) = \textbf{y}(k) -\textbf{y}_m(k)$, has dynamics <br>
							&nbsp; &nbsp; $\dot{\textbf{e}}(k)= \textbf{A}_m\textbf{e}(k) + \textbf{B} \Lambda[\tilde{\textbf{K}}_r^T \textbf{r} +\tilde{\textbf{K}}_y^T \textbf{y} - \varepsilon_f] $,
							<ul>
								<small><li>
								$\textbf{A}_m$ is Hurwitz and known, $\textbf{B}$ is known. &nbsp; $\textbf{y}_m$ is assumed to be a linear model-following model of the form, $\dot{\textbf{y}}_m = \textbf{A}_m \textbf{y}_m + \textbf{B} \, \textbf{r}$.
								</li></small>
							</ul>
						</li></small><br></br>

						<h4><center> Lyapunov Redesign</center></h4>
						<small><li>$\textbf{Theorem:}$<br>							
							Given correct choice of adaptive gains $\hat{\textbf{K}}_y$ and $\hat{\textbf{K}}_r$, the error state vector, $\textbf{e}(k)$ with closed loop time derivative $\dot{\textbf{e}}$, is <i><u><b>uniformly ultimately bounded</b></u></i>, and the state $\textbf{y}$ will converge to a neighborhood of $\textbf{r}$.
							<ul>
								<li>See proof in <a href="http://ecs.utdallas.edu/~opo140030/media/Papers/iROS2017/iROS2017.pdf">text ($\S V.A$)</a>.</li>
							</ul>
						</li>
					</small>

					</ul>
				</section>

				<section data-background="#212F3C" data-background-transition="zoom">
					<h4>Stability Analysis</h4>
					<ul>
						<small><li>Given the Lyapunov function <br>
							&nbsp; &nbsp; &nbsp; &nbsp; $\textbf{V}(\textbf{e}, \tilde{\textbf{K}}_y, \tilde{\textbf{K}}_r) = \textbf{e}^T\textbf{P}\textbf{e} 
							+ \textbf{tr}(\tilde{\textbf{K}}_y^T  \Gamma_y ^{-1}  \tilde{\textbf{K}}_y |\Lambda|) 
							+ \textbf{tr}(\tilde{\textbf{K}}_r^T \Gamma_r^{-1} \tilde{\textbf{K}}_r^T |\Lambda|)$, 
						<ul>
							<small><li>where $\tilde{\textbf{K}}_y = \hat{\textbf{K}}_y - {\textbf{K}}_y$ and $\tilde{\textbf{K}}_r = \hat{\textbf{K}}_r - {\textbf{K}}_r$. <br>

							$\textbf{P}$ is a unique symmetric, positive definite (SPD) matrix solution of the algebraic Lyapunov equation, $\textbf{P}\textbf{A}_m + \textbf{A}_m^T\textbf{P} = -\textbf{Q}$ </li></small>
						</ul>
						</li>
						</small>
						<br></br>

						<small><li>We can verify that the adaptation laws are <br>
								 &nbsp; &nbsp; &nbsp; &nbsp; $\dot{\hat{\textbf{K}}}_y = -\Gamma_y \textbf{y} \textbf{e}^T \textbf{P} \, \textbf{B} \text{sgn}(\Lambda) \text{ and }  
									\dot{\hat{\textbf{K}}}_r = -\Gamma_r \textbf{r} \textbf{e}^T \textbf{P} \, \textbf{B} \, \text{sgn}(\Lambda)$.
								<ul><br>
									<small><li>where $\Gamma_y$ and $\Gamma_r$ are fixed SPD matrices of adaptation rates. &nbsp;
										$\textbf{tr}(\textbf{A})$ denote the trace of matrix $\textbf{A}$.
									</li></small>
								</ul>
								</li></small><br></br>

								<small><li>We show in the paper that the time-derivative of the Lyapunov function is negative definite outside of the compact set <br>
									&nbsp; &nbsp; &nbsp; &nbsp; $\chi =\left(\textbf{e}: \|\textbf{e}\| \le \frac{2\|\textbf{PB}\|\lambda_{high}(\Lambda)\varepsilon_{max}(\textbf{y})}{\lambda_{low}(\textbf{Q})}\right).$</li></small><br></br>

								<small><li>Thus, the error $\textbf{e}$ is &nbsp; <i><u><b>uniformly ultimately bounded.</u></b></i>
								<ul>
									<li>
										$i.e.$ $\textbf{y}(t) \rightarrow 0$ as $t \rightarrow \infty$ is sufficient for us.
									</li>	
								</ul>
								</li></small>
					</ul>
				</section>
			</section>

			<section>
				<section data-background="#212F3C" data-background-transition="zoom">
					<h3>Results</h3>
					<div class="fig figcenter fighighlight">
					  <img src="images/UTSW2017/netloss.jpg" width="49%" height="250" style="border-left: 1px solid black;" align="left"/> 
					  <img src="images/UTSW2017/expt2a.jpg" width="49%" height="250" style="border-left: 1px solid black;">
					  <img src="images/UTSW2017/expt2b.jpg" width="79%" height="250" style="border-left: 1px solid black;">
					</div>

					<aside class="notes" data-markdown>
						### Discuss Results

						- Function Approximator shows good "remembrance properties" baed on unit of measure of goodness of approximation of system

						- Head tracks trajectory to submillimeter accuracy 
					</aside>
				</section>
<!-- 
				<section data-background="#212F3C" data-background-transition="zoom">
					<h4> Experiment I Video <br></h4>
					<video controls="controls" width="800" height="480" name="Video Name" src="videos/UTSW2017/3BladdersSeqActuation0.2.mp4"></video>

					<iframe width="560" height="315" src="https://www.youtube.com/embed/9HN_NDmZjBc" frameborder="0" allowfullscreen></iframe>
				</section>

				<section data-background="#212F3C" data-background-transition="zoom">
					<h4>Expt II Video<br></h4>

					<iframe width="560" height="315" src="https://www.youtube.com/embed/XNRVRwdEvaE" frameborder="0" allowfullscreen></iframe>

					<aside class="notes">

					</aside>
				</section>


	 -->		<section data-background="#212F3C" data-background-transition="zoom">
					<h3>Future/Ongoing Work</h3>
					<ul>
						<li>
							Add a differentiable optimization layer before neural network output layer to account for valve saturation in the end-to-end trianing algorithm
						</li><br>

						<li>
							Test on varied head shapes, sizes and volunteer trials
						</li><br>

						<li>
							Decouple control laws along individual axes of actuation
						</li><br>
					</ul>

				</section>
	 			<section>
					<h3>Stages of Integration</h3>
					<ol>						
						<img src="images/UTSW2017/future.jpg" alt="" />
						<small><li>
							A commercial pillow tested on a mannequin testbed to study controllability along a 1-DoF motion [arXiv:1506.04787, arXiv:1610.01481].
						</li></small><br></br>

						<small><li>
							We then developed and integrated a customized adjustable frame with air pillows to dynamically compensate motions [arXiv:1703.03821]
						</li></small><br></br>

						<small><li>
							Next phase: A wearable head helmet consisting of compliant soft actuating robots with morphological computational properties to actuate along peripheral axes of motion
						</li></small>

					</ol>

				</section>
			</section>

			<section>
				<section>
					<p><a href="UTSW2017.html/?print-pdf/gi">Questions?</a></p>
					<iframe src="UTSW2017.html" width="465" height="385" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:3px solid #666; margin-bottom:5px; max-width: 100%;" allowfullscreen> </iframe>

					<ul>
						<small><li>
							ArXiv Paper ID: 1703.03821v1
						</li></small><br>

						<small><li>
							Presentation citations are fully listed in the paper
						</li></small>
					</ul>
				</section>	
			</section>		

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// // Full list of configuration options available at:
			// // https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				// Display the page number of the current slide
				slideNumber: true,

				// Push each slide change to the browser history
				history: true,

				// Enable keyboard shortcuts for navigation
				keyboard: true,
				// Turns fragments on and off globally
				fragments: true,
				// Enable the slide overview mode
				overview: true,
				// Enables touch navigation on devices with touch input
				touch: true,
				// Flags if speaker notes should be visible to all viewers
				showNotes: false,
				// Flags if speaker notes should be visible to all viewers
				// showNotes: false,
				// Number of milliseconds between automatically proceeding to the
				// next slide, disabled when set to 0, this value can be overwritten
				// by using a data-autoslide attribute on your slides
				 autoSlide: 1500,	
				// Stop auto-sliding after user input
				autoSlideStoppable: true,
				// Opens links in an iframe preview overlay
    			previewLinks: true,
				// Enable slide navigation via mouse wheel
				// mouseWheel: true
				// // Hides the address bar on mobile devices
				 hideAddressBar: true,
				// Parallax background image
				parallaxBackgroundImage: '', // e.g. "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'"

				// Parallax background size
				parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px"

				// Number of pixels to move the parallax background per slide
				// - Calculated automatically unless specified
				// - Set to 0 to disable movement along an axis
				parallaxBackgroundHorizontal: null,
				parallaxBackgroundVertical: null,
				math: {
				    mathjax: 'https://cdn.mathjax.org/mathjax/latest/MathJax.js',
				    config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
				},

				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Transition speed
				transitionSpeed: 'default', // default/fast/slow

				// Transition style for full page slide backgrounds
				backgroundTransition: 'fade', // none/fade/slide/convex/concave/zoom

				// Number of slides away from the current that are visible
				viewDistance: 3,

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true },					
					// MathJax
					{ src: 'plugin/math/math.js', async: true }
				]
			});
		</script>

	</body>
</html>
